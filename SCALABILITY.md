# Guia de Escalabilidade - Sistema Litoral

Este documento descreve as t√©cnicas escal√°veis implementadas no sistema Litoral para suportar alta carga e crescimento.

## üöÄ T√©cnicas Implementadas

### 1. **Clustering e Load Balancing**
- **Node.js Clustering**: Utiliza todos os cores da CPU
- **Nginx Load Balancer**: Distribui requisi√ß√µes entre m√∫ltiplas inst√¢ncias
- **Docker Compose**: Orquestra√ß√£o de m√∫ltiplos containers
- **Kubernetes**: Deploy escal√°vel em produ√ß√£o

### 2. **Cache Distribu√≠do**
- **Redis**: Cache distribu√≠do para sess√µes e dados
- **Smart Cache**: Cache inteligente com invalida√ß√£o autom√°tica
- **Cache por Rota**: TTL espec√≠fico para diferentes endpoints
- **Cache de API**: Reduz carga no banco de dados

### 3. **Rate Limiting Distribu√≠do**
- **Rate Limiter Flexible**: Controle avan√ßado de taxa
- **Limites por Endpoint**: Diferentes limites para cada rota
- **Limites por Usu√°rio**: Controle baseado em IP e usu√°rio
- **Fallback para Mem√≥ria**: Funciona mesmo sem Redis

### 4. **Monitoramento e Observabilidade**
- **Health Checks**: Verifica√ß√£o de sa√∫de dos servi√ßos
- **M√©tricas de Performance**: CPU, mem√≥ria, cache
- **Logs Estruturados**: Logging otimizado por ambiente
- **Graceful Shutdown**: Encerramento seguro dos processos

## üì¶ Op√ß√µes de Deploy

### Op√ß√£o 1: Docker Compose (Desenvolvimento/Staging)

```bash
# 1. Construir as imagens
docker-compose build

# 2. Iniciar todos os servi√ßos
docker-compose up -d

# 3. Verificar status
docker-compose ps

# 4. Ver logs
docker-compose logs -f api-server-1

# 5. Escalar servi√ßos
docker-compose up -d --scale api-server-1=3 --scale api-server-2=3
```

**Servi√ßos inclu√≠dos:**
- 2x API Servers (Node.js)
- 1x Frontend (React + Nginx)
- 1x Load Balancer (Nginx)
- 1x Redis (Cache)
- 1x MongoDB (Banco)

### Op√ß√£o 2: PM2 (Produ√ß√£o Simples)

```bash
# 1. Instalar PM2 globalmente
npm install -g pm2

# 2. Instalar depend√™ncias
cd server && npm install --production

# 3. Iniciar com PM2
pm2 start ecosystem.config.js --env production

# 4. Monitorar
pm2 monit

# 5. Ver logs
pm2 logs litoral-api

# 6. Restart graceful
pm2 reload litoral-api
```

### Op√ß√£o 3: Kubernetes (Produ√ß√£o Escal√°vel)

```bash
# 1. Aplicar configura√ß√µes
kubectl apply -f k8s-deployment.yaml

# 2. Verificar pods
kubectl get pods -n litoral

# 3. Verificar servi√ßos
kubectl get services -n litoral

# 4. Escalar manualmente
kubectl scale deployment litoral-api --replicas=5 -n litoral

# 5. Ver logs
kubectl logs -f deployment/litoral-api -n litoral

# 6. Port forward para teste
kubectl port-forward service/nginx-lb-service 8080:80 -n litoral
```

## üîß Configura√ß√£o de Ambiente

### Vari√°veis de Ambiente Principais

```bash
# Aplica√ß√£o
NODE_ENV=production
PORT=5000
ENABLE_CLUSTERING=true

# Banco de Dados
MONGODB_URI=mongodb://localhost:27017/litoral

# Cache Redis
REDIS_HOST=localhost
REDIS_PORT=6379
REDIS_PASSWORD=

# Rate Limiting
RATE_LIMIT_WINDOW_MS=900000  # 15 minutos
RATE_LIMIT_MAX_REQUESTS=1000

# Cache TTL (segundos)
CACHE_TTL_PROPERTIES=300     # 5 minutos
CACHE_TTL_NEWS=600          # 10 minutos
CACHE_TTL_USERS=1800        # 30 minutos
```

## üìä Monitoramento

### Endpoints de Monitoramento

- **Health Check**: `GET /health`
- **M√©tricas**: `GET /metrics`
- **Limpar Cache**: `POST /dev/clear-cache` (apenas desenvolvimento)

### Exemplo de Response do Health Check

```json
{
  "status": "UP",
  "timestamp": "2024-01-15T10:30:00.000Z",
  "worker": "1",
  "pid": 12345,
  "cache": "connected",
  "memory": {
    "used": 128,
    "total": 256
  },
  "uptime": 3600
}
```

## üéØ Benchmarks e Performance

### Capacidade Estimada

| Configura√ß√£o | RPS | Usu√°rios Simult√¢neos | Lat√™ncia M√©dia |
|--------------|-----|---------------------|----------------|
| Single Instance | 1,000 | 5,000 | 50ms |
| Docker Compose | 5,000 | 25,000 | 30ms |
| Kubernetes (3 pods) | 15,000 | 75,000 | 20ms |
| Kubernetes (10 pods) | 50,000 | 250,000 | 15ms |

### Teste de Carga

```bash
# Usando Apache Bench
ab -n 10000 -c 100 http://localhost/api/properties/featured

# Usando Artillery
npx artillery quick --count 100 --num 1000 http://localhost/api/properties
```

## üîÑ Auto Scaling

### Kubernetes HPA (Horizontal Pod Autoscaler)

- **CPU**: Escala quando uso > 70%
- **Mem√≥ria**: Escala quando uso > 80%
- **Min Replicas**: 3 (API), 2 (Frontend)
- **Max Replicas**: 10 (API), 5 (Frontend)

### Docker Compose Scaling

```bash
# Escalar API servers
docker-compose up -d --scale api-server-1=5

# Escalar com diferentes configura√ß√µes
docker-compose -f docker-compose.yml -f docker-compose.scale.yml up -d
```

## üõ°Ô∏è Seguran√ßa e Rate Limiting

### Limites por Endpoint

- **API Geral**: 1000 req/15min por IP
- **Login**: 5 req/15min por IP
- **Registro**: 3 req/15min por IP
- **Upload**: 10 req/15min por usu√°rio
- **Busca**: 100 req/15min por IP
- **Criar Propriedade**: 20 req/15min por usu√°rio

### Headers de Seguran√ßa

- **CORS**: Configurado para dom√≠nios espec√≠ficos
- **Helmet**: Headers de seguran√ßa autom√°ticos
- **Rate Limit Headers**: Informa√ß√µes sobre limites

## üö® Troubleshooting

### Problemas Comuns

1. **Redis Desconectado**
   - Verificar se Redis est√° rodando
   - Sistema funciona com fallback para mem√≥ria

2. **Alta Lat√™ncia**
   - Verificar cache hit rate
   - Analisar queries do MongoDB
   - Verificar load balancing

3. **Memory Leaks**
   - Monitorar `/metrics`
   - PM2 restart autom√°tico em 1GB
   - Kubernetes limits configurados

### Comandos √öteis

```bash
# Ver uso de recursos
docker stats

# Logs em tempo real
docker-compose logs -f --tail=100

# Conectar ao Redis
docker exec -it litoral_redis_1 redis-cli

# Backup do MongoDB
docker exec litoral_mongodb_1 mongodump --out /backup

# Verificar conex√µes ativas
ss -tuln | grep :5000
```

## üìà Pr√≥ximos Passos

1. **CDN**: Implementar CloudFlare ou AWS CloudFront
2. **Database Sharding**: Particionar MongoDB
3. **Microservices**: Separar em servi√ßos menores
4. **Message Queue**: Implementar Redis Pub/Sub ou RabbitMQ
5. **Elasticsearch**: Para busca avan√ßada
6. **Prometheus + Grafana**: Monitoramento avan√ßado

---

**Desenvolvido com foco em escalabilidade e performance** üöÄ